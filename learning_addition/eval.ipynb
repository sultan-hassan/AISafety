{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea93f6e-dd07-4033-9185-5c35f7d157d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from transformers import GPT2LMHeadModel\n",
    "from Levenshtein import distance as lev_dist\n",
    "# helper edit distance\n",
    "#def lev_dist(s1, s2):\n",
    "#    return abs(len(s1) - len(s2)) \n",
    "\n",
    "# --- Tokenizer Mapping (Must match training) ---\n",
    "chars = sorted(list(\"0123456789+=\"))\n",
    "char_to_id = {s: i for i, s in enumerate(chars)}\n",
    "id_to_char = {i: s for i, s in enumerate(chars)}\n",
    "\n",
    "def has_carry(a, b):\n",
    "    \"\"\"Detects if an addition problem requires at least one carry.\"\"\"\n",
    "    sa, sb = str(a)[::-1], str(b)[::-1]\n",
    "    max_l = max(len(sa), len(sb))\n",
    "    sa, sb = sa.ljust(max_l, '0'), sb.ljust(max_l, '0')\n",
    "    carry = 0\n",
    "    for i in range(max_l):\n",
    "        if int(sa[i]) + int(sb[i]) + carry >= 10:\n",
    "            return True\n",
    "        carry = (int(sa[i]) + int(sb[i]) + carry) // 10\n",
    "    return False\n",
    "\n",
    "def decode_prediction(model, prompt, max_new=6):\n",
    "    \"\"\"Generates and cleans output with an explicit attention mask.\"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    input_ids = torch.tensor([char_to_id[c] for c in prompt]).unsqueeze(0).to(device)\n",
    "\n",
    "    # attention mask\n",
    "    attention_mask = torch.ones_like(input_ids).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_tokens = model.generate(\n",
    "            input_ids, \n",
    "            attention_mask=attention_mask,      # Pass the mask here\n",
    "            max_new_tokens=max_new, \n",
    "            pad_token_id=char_to_id['='],\n",
    "            eos_token_id=char_to_id['='],      # Explicitly set EOS\n",
    "            do_sample=False                    # Greedy decoding\n",
    "        )\n",
    "    \n",
    "    gen_ids = output_tokens[0][len(input_ids[0]):]\n",
    "    pred_str = \"\"\n",
    "    for tid in gen_ids:\n",
    "        c = id_to_char[tid.item()]\n",
    "        if c in \"0123456789\": \n",
    "            pred_str += c\n",
    "        else: \n",
    "            break\n",
    "    return pred_str\n",
    "\n",
    "def run_eval(model_path, test_file, is_reversed=True):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    \n",
    "    stats = {\n",
    "        \"total\": 0, \"em\": 0, \"mae\": 0, \"edit_dist\": 0,\n",
    "        \"digit_correct\": 0, \"digit_total\": 0,\n",
    "        \"carry_cases\": 0, \"carry_correct\": 0,\n",
    "        \"no_carry_cases\": 0, \"no_carry_correct\": 0\n",
    "    }\n",
    "\n",
    "    with open(test_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line.strip(): continue\n",
    "            \n",
    "            prompt_part, expected_str = line.strip().split('=')\n",
    "            a_val, b_val = map(int, prompt_part.replace('+', ' ').split())\n",
    "            \n",
    "            # 1. Prediction\n",
    "            pred_str = decode_prediction(model, prompt_part + \"=\")\n",
    "            \n",
    "            # 2. Numerical Values (Un-reverse for math logic)\n",
    "            true_num = a_val + b_val\n",
    "            try:\n",
    "                # If result was reversed in training (e.g. 123+456=975), un-reverse to 579\n",
    "                cleaned_pred = pred_str[::-1] if is_reversed else pred_str\n",
    "                pred_num = int(cleaned_pred)\n",
    "            except:\n",
    "                pred_num = 0 \n",
    "\n",
    "            # --- Metrics Calculation ---\n",
    "            stats[\"total\"] += 1\n",
    "            \n",
    "            # Exact Match (String comparison)\n",
    "            if pred_str == expected_str:\n",
    "                stats[\"em\"] += 1\n",
    "            \n",
    "            # MAE (Numerical distance)\n",
    "            stats[\"mae\"] += abs(true_num - pred_num)\n",
    "            \n",
    "            # Edit Distance (String similarity)\n",
    "            stats[\"edit_dist\"] += lev_dist(pred_str, expected_str)\n",
    "            \n",
    "            # Digit-wise Accuracy\n",
    "            max_len = max(len(pred_str), len(expected_str))\n",
    "            p_pad = pred_str.ljust(max_len, ' ')\n",
    "            e_pad = expected_str.ljust(max_len, ' ')\n",
    "            for p, e in zip(p_pad, e_pad):\n",
    "                if p == e: stats[\"digit_correct\"] += 1\n",
    "                stats[\"digit_total\"] += 1\n",
    "            \n",
    "            # Carry-Conditional Accuracy\n",
    "            requires_carry = has_carry(a_val, b_val)\n",
    "            if requires_carry:\n",
    "                stats[\"carry_cases\"] += 1\n",
    "                if pred_str == expected_str: stats[\"carry_correct\"] += 1\n",
    "            else:\n",
    "                stats[\"no_carry_cases\"] += 1\n",
    "                if pred_str == expected_str: stats[\"no_carry_correct\"] += 1\n",
    "\n",
    "    # Final Report Output\n",
    "    print(f\"\\n===== RESULTS FOR {test_file} =====\")\n",
    "    print(f\"Exact Match Accuracy:     {stats['em']/stats['total']:.2%}\")\n",
    "    print(f\"Digit-wise Accuracy:      {stats['digit_correct']/stats['digit_total']:.2%}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {stats['mae']/stats['total']:.2f}\")\n",
    "    print(f\"Average Edit Distance:    {stats['edit_dist']/stats['total']:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "    if stats['no_carry_cases'] > 0:\n",
    "        print(f\"Easy (No Carry) Accuracy: {stats['no_carry_correct']/stats['no_carry_cases']:.2%}\")\n",
    "    if stats['carry_cases'] > 0:\n",
    "        print(f\"Hard (With Carry) Accuracy:{stats['carry_correct']/stats['carry_cases']:.2%}\")\n",
    "    \n",
    "    #return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4db369-a658-4466-8048-de763f4a5fde",
   "metadata": {},
   "source": [
    "### Evaluation data strategy 1 (randomly uniform samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eb5bdf9-f96a-4b8a-b7d7-de181fcaa123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULTS FOR test_id.txt =====\n",
      "Exact Match Accuracy:     100.00%\n",
      "Digit-wise Accuracy:      100.00%\n",
      "Mean Absolute Error (MAE): 0.00\n",
      "Average Edit Distance:    0.00\n",
      "----------------------------------------\n",
      "Easy (No Carry) Accuracy: 100.00%\n",
      "Hard (With Carry) Accuracy:100.00%\n",
      "\n",
      "===== RESULTS FOR test_ood.txt =====\n",
      "Exact Match Accuracy:     0.00%\n",
      "Digit-wise Accuracy:      3.35%\n",
      "Mean Absolute Error (MAE): 10880.65\n",
      "Average Edit Distance:    3.73\n",
      "----------------------------------------\n",
      "Easy (No Carry) Accuracy: 0.00%\n",
      "Hard (With Carry) Accuracy:0.00%\n"
     ]
    }
   ],
   "source": [
    "run_eval(\"./final_model\", \"test_id.txt\")\n",
    "run_eval(\"./final_model\", \"test_ood.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5204c-57b9-49b5-bebd-eb3cfd159859",
   "metadata": {},
   "source": [
    "### Evaluation data strategy 2 (Mixed-Length Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a690989-8eba-417b-b506-59795b8010fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULTS FOR test_id_mixed.txt =====\n",
      "Exact Match Accuracy:     100.00%\n",
      "Digit-wise Accuracy:      100.00%\n",
      "Mean Absolute Error (MAE): 0.00\n",
      "Average Edit Distance:    0.00\n",
      "----------------------------------------\n",
      "Easy (No Carry) Accuracy: 100.00%\n",
      "Hard (With Carry) Accuracy:100.00%\n",
      "\n",
      "===== RESULTS FOR test_ood_mixed.txt =====\n",
      "Exact Match Accuracy:     0.00%\n",
      "Digit-wise Accuracy:      0.00%\n",
      "Mean Absolute Error (MAE): 10940.77\n",
      "Average Edit Distance:    4.62\n",
      "----------------------------------------\n",
      "Easy (No Carry) Accuracy: 0.00%\n",
      "Hard (With Carry) Accuracy:0.00%\n"
     ]
    }
   ],
   "source": [
    "run_eval(\"./final_model_mixed\", \"test_id_mixed.txt\")\n",
    "run_eval(\"./final_model_mixed\", \"test_ood_mixed.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e226199-41b0-48a7-b515-060e7450637d",
   "metadata": {},
   "source": [
    "### Evaluation data strategy 3 (Zero Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccdfd926-9255-4a18-93b9-73a1a35d1946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULTS FOR test_id_padded.txt =====\n",
      "Exact Match Accuracy:     99.50%\n",
      "Digit-wise Accuracy:      99.88%\n",
      "Mean Absolute Error (MAE): 0.50\n",
      "Average Edit Distance:    0.01\n",
      "----------------------------------------\n",
      "Easy (No Carry) Accuracy: 100.00%\n",
      "Hard (With Carry) Accuracy:99.15%\n",
      "\n",
      "===== RESULTS FOR test_ood_padded.txt =====\n",
      "Exact Match Accuracy:     0.00%\n",
      "Digit-wise Accuracy:      48.64%\n",
      "Mean Absolute Error (MAE): 10287.83\n",
      "Average Edit Distance:    2.55\n",
      "----------------------------------------\n",
      "Easy (No Carry) Accuracy: 0.00%\n",
      "Hard (With Carry) Accuracy:0.00%\n"
     ]
    }
   ],
   "source": [
    "run_eval(\"./final_model_padded\", \"test_id_padded.txt\")\n",
    "run_eval(\"./final_model_padded\", \"test_ood_padded.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0e659-385b-47eb-bd41-3639fa548aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
